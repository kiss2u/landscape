use duckdb::Statement;
use duckdb::{params, Connection};
use landscape_common::metric::connect::{
    ConnectGlobalStats, ConnectHistoryQueryParams, ConnectHistoryStatus, ConnectKey, ConnectMetric,
    ConnectSortKey, MetricResolution, SortOrder,
};

pub const SUMMARY_INSERT_SQL: &str = "
    INSERT OR REPLACE INTO conn_summaries (
        create_time, cpu_id, src_ip, dst_ip, src_port, dst_port, l4_proto, l3_proto, flow_id, trace_id,
        last_report_time, total_ingress_bytes, total_egress_bytes, total_ingress_pkts, total_egress_pkts, status
    ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16)
";

pub const METRICS_1H_INSERT_SQL: &str = "
    INSERT OR REPLACE INTO conn_metrics_1h (
        create_time, cpu_id, report_time, 
        ingress_bytes, ingress_packets, egress_bytes, egress_packets, status
    ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8)
";

pub const METRICS_1D_INSERT_SQL: &str = "
    INSERT OR REPLACE INTO conn_metrics_1d (
        create_time, cpu_id, report_time, 
        ingress_bytes, ingress_packets, egress_bytes, egress_packets, status
    ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8)
";

pub fn update_summary_by_metric(
    stmt: &mut Statement,
    metric: &ConnectMetric,
) -> duckdb::Result<usize> {
    let key = &metric.key;
    let event_type_val: u8 = metric.status.clone().into();

    stmt.execute(params![
        key.create_time as i64,
        key.cpu_id as i64,
        metric.src_ip.to_string(),
        metric.dst_ip.to_string(),
        metric.src_port as i64,
        metric.dst_port as i64,
        metric.l4_proto as i64,
        metric.l3_proto as i64,
        metric.flow_id as i64,
        metric.trace_id as i64,
        metric.report_time as i64,
        metric.ingress_bytes as i64,
        metric.egress_bytes as i64,
        metric.ingress_packets as i64,
        metric.egress_packets as i64,
        event_type_val as i64,
    ])
}

pub fn create_summaries_table(conn: &Connection) {
    conn.execute(
        "CREATE TABLE IF NOT EXISTS conn_summaries (
            create_time UBIGINT,
            cpu_id INTEGER,
            src_ip VARCHAR,
            dst_ip VARCHAR,
            src_port INTEGER,
            dst_port INTEGER,
            l4_proto INTEGER,
            l3_proto INTEGER,
            flow_id INTEGER,
            trace_id INTEGER,
            last_report_time UBIGINT,
            total_ingress_bytes UBIGINT,
            total_egress_bytes UBIGINT,
            total_ingress_pkts UBIGINT,
            total_egress_pkts UBIGINT,
            status INTEGER,
            PRIMARY KEY (create_time, cpu_id)
        )",
        [],
    )
    .unwrap();
}

pub fn create_metrics_table(conn: &Connection) -> duckdb::Result<()> {
    conn.execute_batch(
        "
        CREATE TABLE IF NOT EXISTS conn_metrics (
            create_time UBIGINT,
            cpu_id INTEGER,
            report_time BIGINT,
            ingress_bytes BIGINT,
            ingress_packets BIGINT,
            egress_bytes BIGINT,
            egress_packets BIGINT,
            status INTEGER
        );

        CREATE TABLE IF NOT EXISTS conn_metrics_1h (
            create_time UBIGINT,
            cpu_id INTEGER,
            report_time BIGINT,
            ingress_bytes BIGINT,
            ingress_packets BIGINT,
            egress_bytes BIGINT,
            egress_packets BIGINT,
            status INTEGER,
            PRIMARY KEY (create_time, cpu_id, report_time)
        );

        CREATE TABLE IF NOT EXISTS conn_metrics_1d (
            create_time UBIGINT,
            cpu_id INTEGER,
            report_time BIGINT,
            ingress_bytes BIGINT,
            ingress_packets BIGINT,
            egress_bytes BIGINT,
            egress_packets BIGINT,
            status INTEGER,
            PRIMARY KEY (create_time, cpu_id, report_time)
        );
        ",
    )
}

pub fn query_metric_by_key(
    conn: &Connection,
    key: &ConnectKey,
    resolution: MetricResolution,
) -> Vec<ConnectMetric> {
    let table = match resolution {
        MetricResolution::Second => "conn_metrics",
        MetricResolution::Hour => "conn_metrics_1h",
        MetricResolution::Day => "conn_metrics_1d",
    };

    let stmt_str = format!(
        "
        SELECT 
            m.report_time,
            m.ingress_bytes,
            m.ingress_packets,
            m.egress_bytes,
            m.egress_packets,
            m.status,
            s.src_ip,
            s.dst_ip,
            s.src_port,
            s.dst_port,
            s.l4_proto,
            s.l3_proto,
            s.flow_id,
            s.trace_id
        FROM {} m
        JOIN conn_summaries s ON m.create_time = s.create_time AND m.cpu_id = s.cpu_id
        WHERE m.create_time = ?1 AND m.cpu_id = ?2
        ORDER BY m.report_time
    ",
        table
    );

    let mut stmt = conn.prepare(&stmt_str).unwrap();

    let rows = stmt
        .query_map(params![key.create_time as i64, key.cpu_id as i64,], |row| {
            Ok(ConnectMetric {
                key: key.clone(),
                report_time: row.get(0)?,
                ingress_bytes: row.get(1)?,
                ingress_packets: row.get(2)?,
                egress_bytes: row.get(3)?,
                egress_packets: row.get(4)?,
                status: row.get::<_, u8>(5)?.into(),
                src_ip: row.get::<_, String>(6)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
                dst_ip: row.get::<_, String>(7)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
                src_port: row.get::<_, i64>(8)? as u16,
                dst_port: row.get::<_, i64>(9)? as u16,
                l4_proto: row.get::<_, i64>(10)? as u8,
                l3_proto: row.get::<_, i64>(11)? as u8,
                flow_id: row.get::<_, i64>(12)? as u8,
                trace_id: row.get::<_, i64>(13)? as u8,
            })
        })
        .unwrap();

    rows.filter_map(Result::ok).collect()
}

pub fn query_historical_summaries_complex(
    conn: &Connection,
    params: ConnectHistoryQueryParams,
) -> Vec<ConnectHistoryStatus> {
    let mut where_clauses = Vec::new();
    if let Some(start) = params.start_time {
        where_clauses.push(format!("last_report_time >= {}", start));
    }
    if let Some(end) = params.end_time {
        where_clauses.push(format!("last_report_time <= {}", end));
    }
    if let Some(ip) = params.src_ip {
        if !ip.is_empty() {
            where_clauses.push(format!("src_ip LIKE '%{}%'", ip));
        }
    }
    if let Some(ip) = params.dst_ip {
        if !ip.is_empty() {
            where_clauses.push(format!("dst_ip LIKE '%{}%'", ip));
        }
    }
    if let Some(p) = params.port_start {
        where_clauses.push(format!("src_port = {}", p));
    }
    if let Some(p) = params.port_end {
        where_clauses.push(format!("dst_port = {}", p));
    }
    if let Some(p) = params.l3_proto {
        where_clauses.push(format!("l3_proto = {}", p));
    }
    if let Some(p) = params.l4_proto {
        where_clauses.push(format!("l4_proto = {}", p));
    }
    if let Some(p) = params.flow_id {
        where_clauses.push(format!("flow_id = {}", p));
    }

    if let Some(s) = params.status {
        where_clauses.push(format!("status = {}", s));
    }

    let where_stmt = if where_clauses.is_empty() {
        String::new()
    } else {
        format!("WHERE {}", where_clauses.join(" AND "))
    };

    let sort_col = match params.sort_key.unwrap_or_default() {
        ConnectSortKey::Port => "src_port",
        ConnectSortKey::Ingress => "total_ingress_bytes",
        ConnectSortKey::Egress => "total_egress_bytes",
        ConnectSortKey::Time => "create_time",
        ConnectSortKey::Duration => "(last_report_time - create_time)",
    };
    let sort_order_str = match params.sort_order.unwrap_or_default() {
        SortOrder::Asc => "ASC",
        SortOrder::Desc => "DESC",
    };

    let limit_clause =
        if let Some(l) = params.limit { format!("LIMIT {}", l) } else { String::new() };

    let stmt = format!("
        SELECT 
            create_time, cpu_id, src_ip, dst_ip, src_port, dst_port, l4_proto, l3_proto, flow_id, trace_id,
            total_ingress_bytes, total_egress_bytes, total_ingress_pkts, total_egress_pkts, last_report_time, status
        FROM conn_summaries
        {}
        ORDER BY {} {}
        {}
    ", where_stmt, sort_col, sort_order_str, limit_clause);

    let mut stmt = match conn.prepare(&stmt) {
        Ok(s) => s,
        Err(e) => {
            tracing::error!("Failed to prepare SQL: {}, error: {}", stmt, e);
            return Vec::new();
        }
    };

    let rows = stmt.query_map([], |row| {
        let key = ConnectKey {
            create_time: row.get::<_, i64>(0)? as u64,
            cpu_id: row.get::<_, i64>(1)? as u32,
        };
        Ok(ConnectHistoryStatus {
            key,
            src_ip: row.get::<_, String>(2)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
            dst_ip: row.get::<_, String>(3)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
            src_port: row.get::<_, i64>(4)? as u16,
            dst_port: row.get::<_, i64>(5)? as u16,
            l4_proto: row.get::<_, i64>(6)? as u8,
            l3_proto: row.get::<_, i64>(7)? as u8,
            flow_id: row.get::<_, i64>(8)? as u8,
            trace_id: row.get::<_, i64>(9)? as u8,
            total_ingress_bytes: row.get::<_, i64>(10)? as u64,
            total_egress_bytes: row.get::<_, i64>(11)? as u64,
            total_ingress_pkts: row.get::<_, i64>(12)? as u64,
            total_egress_pkts: row.get::<_, i64>(13)? as u64,
            last_report_time: row.get::<_, i64>(14)? as u64,
            status: row.get::<_, i64>(15)? as u8,
        })
    });

    match rows {
        Ok(r) => r.filter_map(Result::ok).collect(),
        Err(e) => {
            tracing::error!("Failed to execute query: {}", e);
            Vec::new()
        }
    }
}

pub fn current_active_connect_keys(conn: &Connection) -> Vec<ConnectKey> {
    let stmt = "
        SELECT create_time, cpu_id
        FROM conn_summaries
        WHERE status = 1
    ";

    let mut stmt = match conn.prepare(stmt) {
        Ok(s) => s,
        Err(e) => {
            tracing::error!("Failed to prepare SQL for active connects: {}", e);
            return Vec::new();
        }
    };

    let rows = stmt.query_map([], |row| {
        Ok(ConnectKey {
            create_time: row.get::<_, i64>(0)? as u64,
            cpu_id: row.get::<_, i64>(1)? as u32,
        })
    });

    match rows {
        Ok(r) => r.filter_map(Result::ok).collect(),
        Err(e) => {
            tracing::error!("Failed to execute active connects query: {}", e);
            Vec::new()
        }
    }
}

pub fn query_global_stats(conn: &Connection) -> ConnectGlobalStats {
    let stmt = "
        SELECT 
            SUM(total_ingress_bytes), 
            SUM(total_egress_bytes), 
            SUM(total_ingress_pkts), 
            SUM(total_egress_pkts), 
            COUNT(*) 
        FROM conn_summaries
    ";

    let mut stmt = match conn.prepare(stmt) {
        Ok(s) => s,
        Err(e) => {
            tracing::error!("Failed to prepare SQL for global stats: {}", e);
            return ConnectGlobalStats::default();
        }
    };

    let res = stmt.query_row([], |row| {
        Ok(ConnectGlobalStats {
            total_ingress_bytes: row.get::<_, Option<i64>>(0)?.unwrap_or(0) as u64,
            total_egress_bytes: row.get::<_, Option<i64>>(1)?.unwrap_or(0) as u64,
            total_ingress_pkts: row.get::<_, Option<i64>>(2)?.unwrap_or(0) as u64,
            total_egress_pkts: row.get::<_, Option<i64>>(3)?.unwrap_or(0) as u64,
            total_connect_count: row.get::<_, i64>(4)? as u64,
            last_calculate_time: chrono::Utc::now().timestamp_millis() as u64,
        })
    });

    res.unwrap_or_default()
}

pub fn collect_and_cleanup_old_metrics(
    conn: &Connection,
    cutoff_raw: u64,
    cutoff_1h: u64,
    cutoff_1d: u64,
) -> Box<Vec<ConnectMetric>> {
    // Fetch expired metric records
    let stmt = "
        SELECT 
            s.create_time, s.cpu_id, s.src_ip, s.dst_ip, s.src_port, s.dst_port, s.l4_proto, s.l3_proto, s.flow_id, s.trace_id,
            m.report_time, m.ingress_bytes, m.ingress_packets, m.egress_bytes, m.egress_packets, m.status
        FROM conn_metrics m
        JOIN conn_summaries s ON m.create_time = s.create_time AND m.cpu_id = s.cpu_id
        WHERE m.report_time < ?1
    ";

    let mut stmt = conn.prepare(stmt).unwrap();

    let metrics = stmt
        .query_map([cutoff_raw as i64], |row| {
            let key = ConnectKey {
                create_time: row.get::<_, i64>(0)? as u64,
                cpu_id: row.get::<_, i64>(1)? as u32,
            };

            Ok(ConnectMetric {
                key,
                src_ip: row.get::<_, String>(2)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
                dst_ip: row.get::<_, String>(3)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
                src_port: row.get::<_, i64>(4)? as u16,
                dst_port: row.get::<_, i64>(5)? as u16,
                l4_proto: row.get::<_, i64>(6)? as u8,
                l3_proto: row.get::<_, i64>(7)? as u8,
                flow_id: row.get::<_, i64>(8)? as u8,
                trace_id: row.get::<_, i64>(9)? as u8,
                report_time: row.get(10)?,
                ingress_bytes: row.get(11)?,
                ingress_packets: row.get(12)?,
                egress_bytes: row.get(13)?,
                egress_packets: row.get(14)?,
                status: row.get::<_, u8>(15)?.into(),
            })
        })
        .unwrap()
        .filter_map(Result::ok)
        .collect::<Vec<_>>();

    // Delete expired metric records
    let deleted_metrics = conn
        .execute("DELETE FROM conn_metrics WHERE report_time < ?1", params![cutoff_raw as i64])
        .unwrap();

    let _ = conn
        .execute("DELETE FROM conn_metrics_1h WHERE report_time < ?1", params![cutoff_1h as i64])
        .unwrap();
    let _ = conn
        .execute("DELETE FROM conn_metrics_1d WHERE report_time < ?1", params![cutoff_1d as i64])
        .unwrap();

    let size = conn
        .prepare("SELECT COUNT(*) FROM conn_metrics")
        .unwrap()
        .query_row([], |row| row.get::<_, usize>(0))
        .unwrap();
    tracing::info!(
        "Cleanup complete: deleted {} metric records, remaining: {}",
        deleted_metrics,
        size
    );

    let deleted_summaries = conn
        .execute(
            "DELETE FROM conn_summaries WHERE last_report_time < ?1",
            params![cutoff_1d as i64],
        )
        .unwrap_or(0);
    tracing::info!(
        "Cleanup summaries complete: deleted {} connect_summaries records",
        deleted_summaries
    );

    Box::new(metrics)
}

pub fn query_connection_ip_history(
    conn: &Connection,
    params: ConnectHistoryQueryParams,
    is_src: bool,
) -> Vec<landscape_common::metric::connect::IpHistoryStat> {
    let mut where_clauses = Vec::new();
    if let Some(start) = params.start_time {
        where_clauses.push(format!("last_report_time >= {}", start));
    }
    if let Some(end) = params.end_time {
        where_clauses.push(format!("last_report_time <= {}", end));
    }
    if let Some(p) = params.flow_id {
        where_clauses.push(format!("flow_id = {}", p));
    }
    if let Some(ip) = params.src_ip {
        if !ip.is_empty() {
            where_clauses.push(format!("src_ip LIKE '%{}%'", ip));
        }
    }
    if let Some(ip) = params.dst_ip {
        if !ip.is_empty() {
            where_clauses.push(format!("dst_ip LIKE '%{}%'", ip));
        }
    }

    let where_stmt = if where_clauses.is_empty() {
        String::new()
    } else {
        format!("WHERE {}", where_clauses.join(" AND "))
    };

    let group_col = if is_src { "src_ip" } else { "dst_ip" };

    let sort_col = match params.sort_key.unwrap_or_default() {
        ConnectSortKey::Ingress => "SUM(total_ingress_bytes)",
        ConnectSortKey::Egress => "SUM(total_egress_bytes)",
        ConnectSortKey::Time => "COUNT(*)",
        _ => "SUM(total_egress_bytes)",
    };
    let sort_order_str = match params.sort_order.unwrap_or_default() {
        SortOrder::Asc => "ASC",
        SortOrder::Desc => "DESC",
    };

    let limit_clause =
        if let Some(l) = params.limit { format!("LIMIT {}", l) } else { "LIMIT 50".to_string() };

    let stmt = format!(
        "
        SELECT 
            {}, 
            flow_id,
            SUM(total_ingress_bytes), 
            SUM(total_egress_bytes), 
            SUM(total_ingress_pkts), 
            SUM(total_egress_pkts), 
            COUNT(*)
        FROM conn_summaries
        {}
        GROUP BY {}, flow_id
        ORDER BY {} {}
        {}
    ",
        group_col, where_stmt, group_col, sort_col, sort_order_str, limit_clause
    );

    let mut stmt = match conn.prepare(&stmt) {
        Ok(s) => s,
        Err(e) => {
            tracing::error!("Failed to prepare IP history SQL: {}, error: {}", stmt, e);
            return Vec::new();
        }
    };

    let rows = stmt.query_map([], |row| {
        Ok(landscape_common::metric::connect::IpHistoryStat {
            ip: row.get::<_, String>(0)?.parse().unwrap_or("0.0.0.0".parse().unwrap()),
            flow_id: row.get::<_, i64>(1)? as u8,
            total_ingress_bytes: row.get::<_, Option<i64>>(2)?.unwrap_or(0) as u64,
            total_egress_bytes: row.get::<_, Option<i64>>(3)?.unwrap_or(0) as u64,
            total_ingress_pkts: row.get::<_, Option<i64>>(4)?.unwrap_or(0) as u64,
            total_egress_pkts: row.get::<_, Option<i64>>(5)?.unwrap_or(0) as u64,
            connect_count: row.get::<_, i64>(6)? as u32,
        })
    });

    match rows {
        Ok(r) => r.filter_map(Result::ok).collect(),
        Err(e) => {
            tracing::error!("Failed to execute IP history query: {}", e);
            Vec::new()
        }
    }
}
